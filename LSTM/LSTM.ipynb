{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Dataset with LSTM"
      ],
      "metadata": {
        "id": "Ojk6U6CuP7mW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import Counter #word frequency calculations\n",
        "from itertools import product #grid search combination\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Sm5fl8sWQVzT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Bu ürün beklentimi fazlasıyla karşıladı. Malzeme kalitesi gerçekten çok iyi. Kargo hızlı ve sorunsuz bir şekilde elime ulaitı. Fiyatına göre performansı harika. Kesinlikle tavsiye ederim!\"\"\""
      ],
      "metadata": {
        "id": "11dGsL61Rg5k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = text.replace(\".\", \"\").replace(\"!\",\"\").lower().split()"
      ],
      "metadata": {
        "id": "Ye6AA1UPRtDM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate word frequencies and index\n",
        "word_counts = Counter(words)\n",
        "vocab = sorted(word_counts, key=word_counts.get, reverse=True) #order word frequencies most to lowest\n",
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "ix_to_word = {i: word for i, word in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "1xpNLVRzR4tx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training dataset preparation\n",
        "data = [(words[i], words[i+1]) for i in range(len(words)-1)]"
      ],
      "metadata": {
        "id": "7pQBrsmFSU6f"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define LSTM model"
      ],
      "metadata": {
        "id": "E99aFQUfQG5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "    super(LSTM, self).__init__() #call constructor of higher class\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "    self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x)  #input to embedding\n",
        "    lstm_out, _ = self.lstm(x.view(1,1,-1)) #input to lstm\n",
        "    output = self.fc(lstm_out.view(1,-1))\n",
        "    return output\n",
        "\n",
        "model = LSTM(len(vocab), embedding_dim=8, hidden_dim=32)"
      ],
      "metadata": {
        "id": "D5JsUPxHSyy9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "RROHnDDWQIvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_seq(seq, to_ix): #word list to tensor\n",
        "  return torch.tensor([to_ix[w] for w in seq], dtype = torch.long)\n",
        "\n",
        "#decide hyperparameter tuning combinations\n",
        "embedding_sizes = [8, 16]\n",
        "hidden_sizes = [32, 64]\n",
        "learning_rates = [0.01,0.005]\n",
        "\n",
        "best_loss = float(\"inf\") #lowest loss value (infinity at the beginning)\n",
        "best_params = {}\n",
        "\n",
        "print(\"Hyperparameter tuning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCm85S67T4D4",
        "outputId": "a9ca0b8d-98b9-4069-843e-5bd6e0272f33"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameter tuning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for emb_size, hidden_size, lr in product(embedding_sizes, hidden_sizes, learning_rates):\n",
        "  print(f\"Test: Embedding: {emb_size}, Hidden: {hidden_size}, Learning Rate: {lr}\")\n",
        "  model = LSTM(len(vocab), emb_size, hidden_size)\n",
        "  loss_function = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  epochs = 50\n",
        "  total_loss = 0\n",
        "  for epoch in range(epochs):\n",
        "    epoch_loss = 0\n",
        "    for word, next_word in data:\n",
        "      model.zero_grad()\n",
        "      input_tensor = prep_seq([word], word_to_ix)\n",
        "      target_tensor = prep_seq([next_word], word_to_ix)\n",
        "      output = model(input_tensor)\n",
        "      loss = loss_function(output, target_tensor)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "      print(f\"Epoch: {epoch}, Loss: {epoch_loss:.5f}\")\n",
        "\n",
        "  if total_loss < best_loss:\n",
        "    best_loss = total_loss\n",
        "    best_params = {\"embedding_size\": emb_size, \"hidden_size\": hidden_size, \"learning_rate\": lr}\n",
        "  print()\n",
        "\n",
        "print(f\"Best parameters: {best_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWcL0L8SU8qD",
        "outputId": "efacd15c-e1d8-4758-9446-a26dde828d43"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: Embedding: 8, Hidden: 32, Learning Rate: 0.01\n",
            "Epoch: 0, Loss: 79.38929\n",
            "Epoch: 10, Loss: 1.95750\n",
            "Epoch: 20, Loss: 0.43242\n",
            "Epoch: 30, Loss: 0.20188\n",
            "Epoch: 40, Loss: 0.11909\n",
            "\n",
            "Test: Embedding: 8, Hidden: 32, Learning Rate: 0.005\n",
            "Epoch: 0, Loss: 78.15204\n",
            "Epoch: 10, Loss: 13.32028\n",
            "Epoch: 20, Loss: 2.08681\n",
            "Epoch: 30, Loss: 0.83645\n",
            "Epoch: 40, Loss: 0.46268\n",
            "\n",
            "Test: Embedding: 8, Hidden: 64, Learning Rate: 0.01\n",
            "Epoch: 0, Loss: 79.27559\n",
            "Epoch: 10, Loss: 0.54903\n",
            "Epoch: 20, Loss: 0.14177\n",
            "Epoch: 30, Loss: 0.06746\n",
            "Epoch: 40, Loss: 0.03981\n",
            "\n",
            "Test: Embedding: 8, Hidden: 64, Learning Rate: 0.005\n",
            "Epoch: 0, Loss: 78.37150\n",
            "Epoch: 10, Loss: 3.84254\n",
            "Epoch: 20, Loss: 0.55081\n",
            "Epoch: 30, Loss: 0.23443\n",
            "Epoch: 40, Loss: 0.13192\n",
            "\n",
            "Test: Embedding: 16, Hidden: 32, Learning Rate: 0.01\n",
            "Epoch: 0, Loss: 78.67019\n",
            "Epoch: 10, Loss: 1.10942\n",
            "Epoch: 20, Loss: 0.28933\n",
            "Epoch: 30, Loss: 0.13987\n",
            "Epoch: 40, Loss: 0.08370\n",
            "\n",
            "Test: Embedding: 16, Hidden: 32, Learning Rate: 0.005\n",
            "Epoch: 0, Loss: 78.06287\n",
            "Epoch: 10, Loss: 5.96963\n",
            "Epoch: 20, Loss: 1.03013\n",
            "Epoch: 30, Loss: 0.45696\n",
            "Epoch: 40, Loss: 0.26327\n",
            "\n",
            "Test: Embedding: 16, Hidden: 64, Learning Rate: 0.01\n",
            "Epoch: 0, Loss: 78.77813\n",
            "Epoch: 10, Loss: 0.35231\n",
            "Epoch: 20, Loss: 0.10129\n",
            "Epoch: 30, Loss: 0.04940\n",
            "Epoch: 40, Loss: 0.02945\n",
            "\n",
            "Test: Embedding: 16, Hidden: 64, Learning Rate: 0.005\n",
            "Epoch: 0, Loss: 78.40453\n",
            "Epoch: 10, Loss: 1.59107\n",
            "Epoch: 20, Loss: 0.33934\n",
            "Epoch: 30, Loss: 0.15536\n",
            "Epoch: 40, Loss: 0.09021\n",
            "\n",
            "Best parameters: {'embedding_size': 8, 'hidden_size': 32, 'learning_rate': 0.01}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM training"
      ],
      "metadata": {
        "id": "tGBnx5R4Wy9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = LSTM(len(vocab), best_params[\"embedding_size\"], best_params[\"hidden_size\"])\n",
        "optimizer = optim.Adam(final_model.parameters(), lr=best_params[\"learning_rate\"])\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "  epoch_loss = 0\n",
        "  for word, next_word in data:\n",
        "    final_model.zero_grad()\n",
        "    input_tensor = prep_seq([word], word_to_ix)\n",
        "    target_tensor = prep_seq([next_word], word_to_ix)\n",
        "    output = final_model(input_tensor)\n",
        "    loss = loss_function(output, target_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Final model: Epoch: {epoch}, Loss: {epoch_loss:.5f}\")"
      ],
      "metadata": {
        "id": "xw-XYKInW0D-",
        "outputId": "31ba8bff-5354-45e3-c37f-fa954cbcb761",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final model: Epoch: 0, Loss: 79.29201\n",
            "Final model: Epoch: 10, Loss: 2.38800\n",
            "Final model: Epoch: 20, Loss: 0.47853\n",
            "Final model: Epoch: 30, Loss: 0.22010\n",
            "Final model: Epoch: 40, Loss: 0.12934\n",
            "Final model: Epoch: 50, Loss: 0.08565\n",
            "Final model: Epoch: 60, Loss: 0.06087\n",
            "Final model: Epoch: 70, Loss: 0.04532\n",
            "Final model: Epoch: 80, Loss: 0.03486\n",
            "Final model: Epoch: 90, Loss: 0.02748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing and Evaluation"
      ],
      "metadata": {
        "id": "jtZ2GyqpQT34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#word prediction function: give start word and generate n words\n",
        "def pred_seq(start_word, num_words):\n",
        "  current_word = start_word\n",
        "  output_sequence = [current_word]\n",
        "\n",
        "  for _ in range(num_words):\n",
        "    with torch.no_grad():\n",
        "      input_tensor = prep_seq([current_word], word_to_ix)\n",
        "      output = final_model(input_tensor)\n",
        "      predicted_ix = torch.argmax(output).item() #highest prob word's index\n",
        "      predicted_word = ix_to_word[predicted_ix] #return index's word\n",
        "      output_sequence.append(predicted_word)\n",
        "      current_word = predicted_word #update word for next prediction\n",
        "\n",
        "  return output_sequence\n",
        "\n",
        "start_word = \"ürün\"\n",
        "num_predictions = 10\n",
        "predicted_sequence = pred_seq(start_word, num_predictions)\n",
        "print(\" \".join(predicted_sequence))"
      ],
      "metadata": {
        "id": "U-u9CdNIXmFd",
        "outputId": "2a2db3ce-87cc-4d78-b911-e2124d7a9819",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ürün beklentimi fazlasıyla karşıladı malzeme kalitesi gerçekten çok iyi kargo hızlı\n"
          ]
        }
      ]
    }
  ]
}